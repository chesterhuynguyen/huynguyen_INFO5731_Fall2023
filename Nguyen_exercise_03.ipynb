{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chesterhuynguyen/huynguyen_INFO5731_Fall2023/blob/main/Nguyen_exercise_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "## The third In-class-exercise (due on 11:59 PM 10/08/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2htC-oV70ne"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "Task:\n",
        "Sentiment analysis of customer reviews for a product or service. Sentiment analysis aims to determine whether a given text expresses a positive, negative, or neutral sentiment.\n",
        "This task is valuable for businesses to understand customer opinions, identify areas for improvement, and make data-driven decisions\n",
        "\n",
        "5 features that can be useful for building a machine learning model for sentiment analysis:\n",
        "\n",
        "- Word Frequency: Counting the frequency of specific words or phrases in the text can be informative. Positive or negative sentiment often correlates with certain keywords. For example, words like \"excellent,\" \"amazing,\" or \"terrible\" are strong indicators of sentiment.\n",
        "\n",
        "- N-grams: N-grams are sequences of adjacent words in a text. Analyzing bi-grams (two-word combinations) or tri-grams (three-word combinations) can capture context and sentiment nuances. For instance, \"not good\" is different from \"very good.\"\n",
        "\n",
        "- Sentiment Lexicons: Sentiment lexicons or dictionaries contain lists of words with associated sentiment scores (positive, negative, neutral). By matching words in the text to this lexicon, you can calculate an overall sentiment score for the document. Lexicons can help handle sarcasm or negations, where the sentiment may be reversed.\n",
        "\n",
        "- Part-of-Speech (POS) Tags: Understanding the grammatical structure of the text can be beneficial. For example, identifying adjectives and adverbs in a sentence can provide insights into the intensity of sentiment. Adjectives like \"great\" or adverbs like \"extremely\" can impact the sentiment score.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e26535-9f46-45ba-b121-65c837c01c28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Frequency:\n",
            "<FreqDist with 18 samples and 21 outcomes>\n",
            "\n",
            "Bi-grams:\n",
            "[('The', 'movie'), ('movie', 'was'), ('was', 'excellent'), ('excellent', '.'), ('.', 'I'), ('I', 'really'), ('really', 'enjoyed'), ('enjoyed', 'it'), ('it', '!'), ('!', 'However'), ('However', ','), (',', 'the'), ('the', 'service'), ('service', 'at'), ('at', 'the'), ('the', 'theater'), ('theater', 'was'), ('was', 'terrible'), ('terrible', 'ðŸ˜¡'), ('ðŸ˜¡', '.')]\n",
            "\n",
            "Tri-grams:\n",
            "[('The', 'movie', 'was'), ('movie', 'was', 'excellent'), ('was', 'excellent', '.'), ('excellent', '.', 'I'), ('.', 'I', 'really'), ('I', 'really', 'enjoyed'), ('really', 'enjoyed', 'it'), ('enjoyed', 'it', '!'), ('it', '!', 'However'), ('!', 'However', ','), ('However', ',', 'the'), (',', 'the', 'service'), ('the', 'service', 'at'), ('service', 'at', 'the'), ('at', 'the', 'theater'), ('the', 'theater', 'was'), ('theater', 'was', 'terrible'), ('was', 'terrible', 'ðŸ˜¡'), ('terrible', 'ðŸ˜¡', '.')]\n",
            "\n",
            "Sentiment Lexicon Score:\n",
            "0.20833333333333334\n",
            "\n",
            "POS Tags:\n",
            "[('The', 'DT'), ('movie', 'NN'), ('was', 'VBD'), ('excellent', 'JJ'), ('.', '.'), ('I', 'PRP'), ('really', 'RB'), ('enjoyed', 'VBD'), ('it', 'PRP'), ('!', '.'), ('However', 'RB'), (',', ','), ('the', 'DT'), ('service', 'NN'), ('at', 'IN'), ('the', 'DT'), ('theater', 'NN'), ('was', 'VBD'), ('terrible', 'JJ'), ('ðŸ˜¡', 'NN'), ('.', '.')]\n",
            "\n",
            "Emoticons/Emojis:\n",
            "['ðŸ˜¡']\n"
          ]
        }
      ],
      "source": [
        "# import nltk library\n",
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "from nltk.util import ngrams\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Sample text data\n",
        "sample_text = \"The movie was excellent. I really enjoyed it! However, the service at the theater was terrible ðŸ˜¡.\"\n",
        "\n",
        "# Tokenize the text\n",
        "words = nltk.word_tokenize(sample_text)\n",
        "\n",
        "# 1. Word Frequency\n",
        "word_frequency = nltk.FreqDist(words)\n",
        "print(\"Word Frequency:\")\n",
        "print(word_frequency)\n",
        "\n",
        "# 2. N-grams (bi-grams and tri-grams)\n",
        "bi_grams = list(ngrams(words, 2))\n",
        "tri_grams = list(ngrams(words, 3))\n",
        "print(\"\\nBi-grams:\")\n",
        "print(bi_grams)\n",
        "print(\"\\nTri-grams:\")\n",
        "print(tri_grams)\n",
        "\n",
        "# 3. Sentiment Lexicons (using TextBlob)\n",
        "tb = TextBlob(sample_text)\n",
        "sentiment_lexicon_score = tb.sentiment.polarity\n",
        "print(\"\\nSentiment Lexicon Score:\")\n",
        "print(sentiment_lexicon_score)\n",
        "\n",
        "# 4. Part-of-Speech (POS) Tags\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "print(\"\\nPOS Tags:\")\n",
        "print(pos_tags)\n",
        "\n",
        "# 5. Emoticons and Emoji (using TextBlob)\n",
        "emojis = [char for char in sample_text if char in \"ðŸ˜ŠðŸ˜¡\"]\n",
        "print(\"\\nEmoticons/Emojis:\")\n",
        "print(emojis)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2CRuXfV570ng"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4HoWK-i70ng"
      },
      "outputs": [],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}